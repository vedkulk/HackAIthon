{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "data=pd.read_csv('Cleaned_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Anxiety': np.int64(0), 'Bipolar': np.int64(1), 'Depression': np.int64(2), 'Normal': np.int64(3), 'Personality disorder': np.int64(4), 'Stress': np.int64(5), 'Suicidal': np.int64(6)}\n",
      "Training samples: 40244, Testing samples: 10061\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset='statement').reset_index(drop=True)\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['status'])\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['statement'], data['label'], test_size=0.2, random_state=42, stratify=data['label']\n",
    ")\n",
    "print(label_mapping)\n",
    "print(f\"Training samples: {len(X_train)}, Testing samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87cf0538765479295ba6404edf627d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utsav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\utsav\\.cache\\huggingface\\hub\\models--microsoft--BiomedNLP-PubMedBERT-base-uncased-abstract. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d2c68073424982bb9b77cac6166d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51423d60123e4213ba7e8fc420d3b383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/225k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    return tokenizer(\n",
    "        list(texts),\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_texts(X_train)\n",
    "test_encodings = tokenize_texts(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b613cf6dd13a41a5b9e29c69e919acb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = data['status'].nunique()\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    num_labels=num_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\")\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(data['status'].unique())}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "data['label'] = data['status'].map(label2id)\n",
    "\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['statement'].tolist(),\n",
    "    data['label'].tolist(),\n",
    "    test_size=0.2,\n",
    "    stratify=data['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "class PsychDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "train_dataset = PsychDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = PsychDataset(val_texts, val_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_labels = len(label2id)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\",\n",
    "    num_labels=num_labels\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2516/2516 [28:25<00:00,  1.47it/s, loss=0.706] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed with average loss: 0.6244616079616504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2516/2516 [28:30<00:00,  1.47it/s, loss=0.13]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed with average loss: 0.41772713388548793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2516/2516 [28:39<00:00,  1.46it/s, loss=0.13]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed with average loss: 0.3206699542332565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./psychbert_model\\\\tokenizer_config.json',\n",
       " './psychbert_model\\\\special_tokens_map.json',\n",
       " './psychbert_model\\\\vocab.txt',\n",
       " './psychbert_model\\\\added_tokens.json',\n",
       " './psychbert_model\\\\tokenizer.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader)*3\n",
    ")\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        loop.set_description(f\"Epoch {epoch+1}\")\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} completed with average loss: {avg_loss}\")\n",
    "\n",
    "model.save_pretrained(\"./psychbert_model\")\n",
    "tokenizer.save_pretrained(\"./psychbert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 93.27%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 96.27%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 81.04%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Suicidal**\n",
      "Confidence: 89.90%\n",
      "Why do I feel this way? âš ï¸ This indicates suicidal ideation, often a result of overwhelming psychological pain and a sense of hopelessness. The brain may feel 'cognitive constriction' â€” a tunnel vision where problems seem insurmountable. Please know: help is available, and these feelings can pass. Contact a mental health helpline immediately or talk to someone who can support you. You are not alone, and you matter deeply.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Bipolar**\n",
      "Confidence: 40.85%\n",
      "Why do I feel this way? This suggests symptoms resembling bipolar disorder, characterized by alternating periods of emotional highs (mania) and lows (depression). During manic phases, impulsivity and overconfidence can dominate; during lows, feelings of despair and lethargy may arise. Mood regulation strategies and long-term professional guidance are essential. Awareness is the first step to stability.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 99.71%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 83.00%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Anxiety**\n",
      "Confidence: 97.87%\n",
      "Why do I feel this way? This indicates anxiety, which is a heightened state of worry or fear of potential threats â€” often even when no immediate danger exists. Your brain's amygdala may be overactive, causing hypervigilance and restlessness. Cognitive reframing, breathing exercises (like the 4-7-8 method), and journaling about worries can help calm this response.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 99.62%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 94.32%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 99.37%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 98.53%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 46.81%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 99.78%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 96.22%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Depression**\n",
      "Confidence: 92.61%\n",
      "Why do I feel this way? You're showing signs of depression â€” a persistent state of low mood, hopelessness, and lack of motivation. It often arises from prolonged stress, unresolved trauma, or neurochemical imbalances (like low serotonin or dopamine). Maintaining structure, seeking connection with others, and engaging in small rewarding activities (behavioral activation) can ease the heaviness. Professional therapy is highly encouraged if these feelings persist.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 81.74%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Suicidal**\n",
      "Confidence: 86.93%\n",
      "Why do I feel this way? âš ï¸ This indicates suicidal ideation, often a result of overwhelming psychological pain and a sense of hopelessness. The brain may feel 'cognitive constriction' â€” a tunnel vision where problems seem insurmountable. Please know: help is available, and these feelings can pass. Contact a mental health helpline immediately or talk to someone who can support you. You are not alone, and you matter deeply.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Suicidal**\n",
      "Confidence: 86.93%\n",
      "Why do I feel this way? âš ï¸ This indicates suicidal ideation, often a result of overwhelming psychological pain and a sense of hopelessness. The brain may feel 'cognitive constriction' â€” a tunnel vision where problems seem insurmountable. Please know: help is available, and these feelings can pass. Contact a mental health helpline immediately or talk to someone who can support you. You are not alone, and you matter deeply.\n",
      "\n",
      "ðŸ§  Psychological Analysis Report:\n",
      "Detected Mental State: **Normal**\n",
      "Confidence: 99.38%\n",
      "Why do I feel this way? Stay mindful and keep taking care of yourself.\n",
      "Take care! Stay mindful. ðŸ’™\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"./psychbert_model\").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./psychbert_model\")\n",
    "\n",
    "explanations = {\n",
    "    \"Stress\": (\n",
    "        \"You're showing signs of stress. This often stems from acute stressors like deadlines, interpersonal conflicts, or overwhelming responsibilities. \"\n",
    "        \"It triggers the 'fight-or-flight' response, leading to irritability, tension, and fatigue. \"\n",
    "        \"Practicing mindfulness, progressive muscle relaxation, and scheduled self-care breaks can help your mind decompress.\"\n",
    "    ),\n",
    "    \n",
    "    \"Anxiety\": (\n",
    "        \"This indicates anxiety, which is a heightened state of worry or fear of potential threats â€” often even when no immediate danger exists. \"\n",
    "        \"Your brain's amygdala may be overactive, causing hypervigilance and restlessness. \"\n",
    "        \"Cognitive reframing, breathing exercises (like the 4-7-8 method), and journaling about worries can help calm this response.\"\n",
    "    ),\n",
    "    \n",
    "    \"Depression\": (\n",
    "        \"You're showing signs of depression â€” a persistent state of low mood, hopelessness, and lack of motivation. \"\n",
    "        \"It often arises from prolonged stress, unresolved trauma, or neurochemical imbalances (like low serotonin or dopamine). \"\n",
    "        \"Maintaining structure, seeking connection with others, and engaging in small rewarding activities (behavioral activation) can ease the heaviness. \"\n",
    "        \"Professional therapy is highly encouraged if these feelings persist.\"\n",
    "    ),\n",
    "    \n",
    "    \"Suicidal\": (\n",
    "        \"âš ï¸ This indicates suicidal ideation, often a result of overwhelming psychological pain and a sense of hopelessness. \"\n",
    "        \"The brain may feel 'cognitive constriction' â€” a tunnel vision where problems seem insurmountable. \"\n",
    "        \"Please know: help is available, and these feelings can pass. Contact a mental health helpline immediately or talk to someone who can support you. \"\n",
    "        \"You are not alone, and you matter deeply.\"\n",
    "    ),\n",
    "    \n",
    "    \"Bipolar\": (\n",
    "        \"This suggests symptoms resembling bipolar disorder, characterized by alternating periods of emotional highs (mania) and lows (depression). \"\n",
    "        \"During manic phases, impulsivity and overconfidence can dominate; during lows, feelings of despair and lethargy may arise. \"\n",
    "        \"Mood regulation strategies and long-term professional guidance are essential. Awareness is the first step to stability.\"\n",
    "    ),\n",
    "    \n",
    "    \"Personality disorder\": (\n",
    "        \"Signs indicate traits associated with personality disorders â€” persistent patterns of thinking, feeling, and behaving that can impact relationships and well-being. \"\n",
    "        \"Examples include borderline tendencies (emotional instability), or narcissistic traits (sensitivity to criticism). \"\n",
    "        \"Developing emotional intelligence and working with a therapist can help in understanding and reshaping these patterns.\"\n",
    "    ),\n",
    "    \n",
    "    \"Neutral\": (\n",
    "        \"Your mental state seems balanced and stable. You're showing signs of psychological well-being, emotional regulation, and resilience. \"\n",
    "        \"Keep nurturing this state through self-awareness, positive affirmations, and healthy routines!\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "def analyze_input(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    probs = F.softmax(logits, dim=1)\n",
    "    predicted_class = torch.argmax(probs, dim=1).item()\n",
    "\n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    label = id2label[predicted_class]\n",
    "    confidence = probs[0][predicted_class].item()\n",
    "    \n",
    "    explanation = explanations.get(label, \"Stay mindful and keep taking care of yourself.\")\n",
    "\n",
    "    print(\"\\nðŸ§  Psychological Analysis Report:\")\n",
    "    print(f\"Detected Mental State: **{label}**\")\n",
    "    print(f\"Confidence: {confidence*100:.2f}%\")\n",
    "    print(f\"Why do I feel this way? {explanation}\")\n",
    "    \n",
    "while True:\n",
    "    user_input = input(\"\\nEnter your thoughts (or type 'exit' to quit): \")\n",
    "    if user_input.lower() == \"exit\":\n",
    "        print(\"Take care! Stay mindful. ðŸ’™\")\n",
    "        break\n",
    "    analyze_input(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2 (v3.12.2:6abddd9f6a, Feb  6 2024, 17:02:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
